{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848445ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('dataset/raw_data.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #visualization\n",
    "import seaborn as sns #visualization\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(data)\n",
    "# generating the profile report and outputting it \n",
    "profile.to_file('profile_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20169ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "train = pd.read_csv('dataset/training.csv')\n",
    "train.head(10)\n",
    "\n",
    "# load the test dataset\n",
    "test = pd.read_csv('dataset/testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f0457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Select features and target variable\n",
    "X_train = train.drop('prognosis', axis=1)  # Features (all columns except the target variable)\n",
    "y_train = train['prognosis']  # Target variable (price)\n",
    "\n",
    "X_test = test.drop('prognosis', axis=1)\n",
    "y_test = test['prognosis']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree regressor\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_diseases = data['Disease'].unique()\n",
    "print(unique_diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the true labels in the variable y_test and predicted labels in the variable y_pred\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert the classification report dictionary to a pandas DataFrame\n",
    "metrics_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Select the metrics for precision and recall for the 10 diseases\n",
    "selected_classes = ['Fungal infection', 'Allergy', 'GERD', 'Chronic cholestasis', 'Drug Reaction',\n",
    "                     'Peptic ulcer diseae', 'AIDS', 'Diabetes ', 'Gastroenteritis', 'Bronchial Asthma']\n",
    "metrics_df = metrics_df.loc[selected_classes, ['precision', 'recall']]\n",
    "\n",
    "# Plot the metrics using a grouped bar chart\n",
    "metrics_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall for 10 Diseases')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a7a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\raw_data.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create an empty dictionary for the symptom-keyword mapping\n",
    "symptom_mapping = {}\n",
    "\n",
    "# Iterate through the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    symptoms = []\n",
    "    keywords = []\n",
    "\n",
    "    # Loop through symptom columns and extract symptom-keyword pairs\n",
    "    for column_name in df.columns:\n",
    "        if column_name.startswith('Symptom_'):\n",
    "            symptom = row[column_name]\n",
    "            if isinstance(symptom, str):  # Check if the value is a string\n",
    "                symptom = symptom.strip()\n",
    "                if symptom:\n",
    "                    symptoms.append(symptom)\n",
    "                    keywords.extend(symptom.split('_'))  # Split keywords and add to the list\n",
    "    \n",
    "    # Populate the symptom-keyword mapping for each symptom\n",
    "    for symptom in symptoms:\n",
    "        symptom_mapping[symptom] = {\n",
    "            \"keywords\": [keyword.strip() for keyword in keywords if keyword.strip()]\n",
    "        }\n",
    "\n",
    "# Now you have your symptom-keyword mapping ready\n",
    "print(symptom_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the second dataset into a DataFrame\n",
    "df2 = pd.read_csv(r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\data_2.csv')  # Replace with your second dataset file\n",
    "\n",
    "df3 = pd.DataFrame(columns=['Disease', 'Symptoms'])\n",
    "\n",
    "current_disease = None\n",
    "current_symptoms = []\n",
    "\n",
    "# Iterate through rows in the second dataset\n",
    "for index, row in df2.iterrows():\n",
    "    if row['Disease'] != current_disease:\n",
    "        # If a new disease is encountered, add the previous disease's data to df3\n",
    "        if current_disease:\n",
    "            df3 = pd.concat([df3, pd.DataFrame({'Disease': [current_disease], 'Symptoms': [', '.join(current_symptoms)]})], ignore_index=True)\n",
    "        # Reset for the new disease\n",
    "        current_disease = row['Disease']\n",
    "        current_symptoms = []\n",
    "    # Add the symptom to the current list\n",
    "    current_symptoms.append(str(row['Symptom']))\n",
    "\n",
    "# Add the last disease's data to df3\n",
    "if current_disease:\n",
    "    df3 = pd.concat([df3, pd.DataFrame({'Disease': [current_disease], 'Symptoms': [', '.join(current_symptoms)]})], ignore_index=True)\n",
    "\n",
    "# Save the reshaped dataset to a new CSV file\n",
    "df3.to_csv(r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\data_3.csv', index=False)\n",
    "\n",
    "print(\"Reshaped dataset has been saved to 'data_3.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8bd84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "files = [r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\data_1.csv', r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\processed_data_2.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "df.to_csv(r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\merged_data.csv', index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abcd69d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Symptom'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3468\\329124868.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Set 'Symptom' column as the index for easy pivoting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Symptom'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Create a new DataFrame by transposing the original DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5503\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5505\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Symptom'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your dataset into a Pandas DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\merged_data.csv', sep=',', encoding='utf-8')\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"The dataset is empty.\")\n",
    "else:\n",
    "    # Set 'Symptom' column as the index for easy pivoting\n",
    "    df.set_index('Symptom', inplace=True)\n",
    "\n",
    "    # Create a new DataFrame by transposing the original DataFrame\n",
    "    new_df = df.transpose()\n",
    "\n",
    "    # Reset the index to make diseases as column headings\n",
    "    new_df.reset_index(inplace=True)\n",
    "\n",
    "    # Rename the 'index' column to 'Disease'\n",
    "    new_df.rename(columns={'index': 'Disease'}, inplace=True)\n",
    "\n",
    "    # Fill NaN values with 0 and set other values to 1\n",
    "    new_df = new_df.notna().astype(int)\n",
    "\n",
    "    # Save the new DataFrame to a new CSV file\n",
    "    new_df.to_csv(r'C:\\Users\\ASUS\\Desktop\\CSE499 Project\\CSE499-Project\\dataset\\preprocessed_dataset.csv', index=False)\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408c32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d8967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
