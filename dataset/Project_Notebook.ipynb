{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f27d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop('Disease', axis=1)\n",
    "y = df['Disease']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier with multiple Decision Trees (n_estimators)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# checking which diseases are predicted wrong \n",
    "# for actual, predicted in zip(y_test, y_pred):\n",
    "#     if actual != predicted:\n",
    "#         print(f\"Actual: {actual}, Predicted: {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83261d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.83\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier with multiple Decision Trees (n_estimators)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abee8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the 'clf' model to a pickle file\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD

   "id": "d472ac17",

=======
<<<<<<< HEAD
=======
<<<<<<< HEAD
   "id": "d472ac17",
=======
<<<<<<< HEAD
   "id": "ef3f6d84",
=======
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "id": "c7b53369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy in g:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in g:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef720a1",
<<<<<<< HEAD

=======
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 7a8519d2f3dd6bb0cb396a7661bcbdafd4fea19f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y: {'Hypothyroidism', 'Osteomyelitis', 'Diverticulosis', 'Tonic-Clonic Seizures', 'Delirium', 'Coronary Heart Disease', 'Pneumonia', 'Anemia', 'Heart attack', 'Cholecystitis', 'Pneumonia Aspiration', 'Diabetes', 'Psychotic Disorder', 'Chicken pox', 'hepatitis A', 'Aphasia', 'Pneumocystiscariniipneumonia', 'Hyperlipidemia', 'Pancreatitis', 'Urinary tract infection', 'Hepatitis', 'Dependence', 'Carcinoma Of Lung', 'Tricuspid Valve Insufficiency', 'Hepatitis D', 'Tachycardia Sinus', 'Obesity Morbid', 'Hypoglycemia', 'Acne', 'Dimorphic hemmorhoids(piles)', 'Benign Prostatic Hypertrophy', 'Suicide Attempt', 'Cervical spondylosis', 'Confusion', 'Epilepsy', 'Fungal infection', 'Common Cold', 'Malignantneoplasms', 'Upper Respiratory Infection', 'Influenza', 'Manic Disorder', 'Carcinoma Breast', 'Diabetes ', 'Paroxysmaldyspnea', 'Chronic Alcoholic Intoxication', 'Pneumothorax', 'Psoriasis', 'Hypertension ', 'Pericardial Effusion Body Substance', 'Primary Malignant Neoplasm', 'Glaucoma', 'Neoplasm', 'Neutropenia', '(vertigo) Paroymsal  Positional Vertigo', 'Impetigo', 'Lymphatic Diseases', 'Malaria', 'Endocarditis', 'Fibroid Tumor', 'Hyperthyroidism', 'Cellulitis', 'Adenocarcinoma', 'Sickle Cell Anemia', 'Embolism Pulmonary', 'Diverticulitis', 'Hyperbilirubinemia', 'Infection Urinary Tract', 'Hypertension Pulmonary', 'Osteoarthristis', 'Neuropathy', 'Kidney Disease', 'Neoplasm Metastasis', 'Cardiomyopathy', 'Bronchitis', 'Gastritis', 'Lymphoma', 'Hemorrhoids', 'Gastroesophageal Reflux Disease', 'Allergy', 'Gastroenteritis', 'Typhoid', 'Arthritis', 'Degenerativepolyarthritis', 'Dengue', 'Mitral Valve Insufficiency', 'Sepsis (Invertebrate)', 'Incontinence', 'Hyperglycemia', 'Drug Reaction', 'Kidney Failure Acute', 'Tuberculosis', 'Carcinoma Prostate', 'Failure Kidney', 'Paranoia', 'Hiv Infections', 'Ketoacidosis Diabetic', 'Delusion', 'Transient Ischemic Attack', 'Melanoma', 'Hepatitis C', 'Ileus', 'Pyelonephritis', 'Emphysema Pulmonary', 'Primary Carcinoma Of The Liver Cells', 'Edema Pulmonary', 'Oralcandidiasis', 'Schizophrenia', 'Thrombocytopaenia', 'Encephalopathy', 'Obesity', 'GERD', 'Insufficiency Renal', 'Ischemia', 'Herniahiatal', 'Paralysis (brain hemorrhage)', 'Carcinoma', 'Pancytopenia', 'Bacteremia', 'Depressive Disorder', 'Bipolar Disorder', 'Dementia', 'Personality Disorder', 'Carcinoma Colon', 'Parkinson Disease', 'Hypercholesterolemia', 'Myocardial Infarction', \"Alzheimer'S Disease\", 'Jaundice', 'Deep Vein Thrombosis', 'Spasm Bronchial', 'Cirrhosis', 'Osteoporosis', 'Varicose veins', 'Hernia', 'Chronic cholestasis', 'Overload Fluid', 'Hepatitis E', 'Migraine', 'AIDS', 'Thrombus', 'Adhesion', 'Bronchial Asthma', 'Failure Heart Congestive', 'Biliary Calculus', 'Asthma', 'Decubitus Ulcer', 'Peptic ulcer diseae', 'Hypertensive Disease', 'Chronic Obstructive Airway Disease', 'Chronic Kidney Failure', 'Ulcer Peptic', 'Dehydration', 'Alcoholic hepatitis', 'Accidentcerebrovascular', 'Stenosis Aortic Valve', 'Affect Labile', 'Hemiparesis', 'Gout', 'Infection', 'Respiratory Failure', 'Colitis', 'Deglutition Disorder', 'Migraine Disorders', 'Anxiety State', 'Failure Heart', 'Exanthema', 'Hepatitis B', 'Peripheral Vascular Disease'}\n",
      "Unique values in y_encoded: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming your target variable is 'y'\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print unique values before and after encoding\n",
    "print(\"Unique values in y:\", set(y))\n",
    "print(\"Unique values in y_encoded:\", set(y_encoded))\n",
    "\n",
    "# Rest of your code...\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 5,
   "id": "95239c1a",

=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "execution_count": 22,
   "id": "2f60ba61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137], got ['(vertigo) Paroymsal  Positional Vertigo' 'AIDS'\n 'Accidentcerebrovascular' 'Acne' 'Adenocarcinoma' 'Affect Labile'\n 'Alcoholic hepatitis' 'Allergy' \"Alzheimer'S Disease\" 'Anxiety State'\n 'Aphasia' 'Arthritis' 'Asthma' 'Bacteremia'\n 'Benign Prostatic Hypertrophy' 'Bipolar Disorder' 'Bronchial Asthma'\n 'Bronchitis' 'Carcinoma Breast' 'Carcinoma Colon' 'Carcinoma Of Lung'\n 'Cardiomyopathy' 'Cervical spondylosis' 'Chicken pox' 'Cholecystitis'\n 'Chronic Alcoholic Intoxication' 'Chronic Kidney Failure'\n 'Chronic cholestasis' 'Cirrhosis' 'Colitis' 'Common Cold' 'Confusion'\n 'Coronary Heart Disease' 'Decubitus Ulcer' 'Deep Vein Thrombosis'\n 'Degenerativepolyarthritis' 'Delusion' 'Dementia' 'Dengue' 'Dependence'\n 'Depressive Disorder' 'Diabetes ' 'Dimorphic hemmorhoids(piles)'\n 'Diverticulitis' 'Diverticulosis' 'Drug Reaction' 'Edema Pulmonary'\n 'Emphysema Pulmonary' 'Encephalopathy' 'Endocarditis' 'Exanthema'\n 'Failure Heart' 'Failure Heart Congestive' 'Failure Kidney'\n 'Fibroid Tumor' 'Fungal infection' 'GERD' 'Gastroenteritis'\n 'Gastroesophageal Reflux Disease' 'Glaucoma' 'Gout' 'Heart attack'\n 'Hemiparesis' 'Hemorrhoids' 'Hepatitis' 'Hepatitis B' 'Hepatitis C'\n 'Hepatitis D' 'Hepatitis E' 'Hernia' 'Hyperbilirubinemia'\n 'Hypercholesterolemia' 'Hyperglycemia' 'Hyperlipidemia' 'Hypertension '\n 'Hypertension Pulmonary' 'Hypertensive Disease' 'Hyperthyroidism'\n 'Hypoglycemia' 'Hypothyroidism' 'Ileus' 'Impetigo' 'Incontinence'\n 'Infection' 'Influenza' 'Insufficiency Renal' 'Ischemia' 'Jaundice'\n 'Ketoacidosis Diabetic' 'Kidney Failure Acute' 'Lymphatic Diseases'\n 'Lymphoma' 'Malaria' 'Malignantneoplasms' 'Manic Disorder' 'Melanoma'\n 'Migraine' 'Migraine Disorders' 'Myocardial Infarction' 'Neoplasm'\n 'Neuropathy' 'Obesity' 'Oralcandidiasis' 'Osteoarthristis'\n 'Osteomyelitis' 'Overload Fluid' 'Pancreatitis' 'Pancytopenia'\n 'Paralysis (brain hemorrhage)' 'Paranoia' 'Parkinson Disease'\n 'Peptic ulcer diseae' 'Pericardial Effusion Body Substance'\n 'Peripheral Vascular Disease' 'Personality Disorder'\n 'Pneumocystiscariniipneumonia' 'Pneumonia' 'Pneumonia Aspiration'\n 'Pneumothorax' 'Primary Carcinoma Of The Liver Cells'\n 'Primary Malignant Neoplasm' 'Psoriasis' 'Psychotic Disorder'\n 'Pyelonephritis' 'Respiratory Failure' 'Schizophrenia'\n 'Sepsis (Invertebrate)' 'Suicide Attempt' 'Tachycardia Sinus' 'Thrombus'\n 'Tonic-Clonic Seizures' 'Transient Ischemic Attack' 'Tuberculosis'\n 'Typhoid' 'Upper Respiratory Infection' 'Urinary tract infection'\n 'Varicose veins' 'hepatitis A']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_932\\4265515747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Make predictions on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1465\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m             ):\n\u001b[1;32m-> 1467\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1468\u001b[0m                     \u001b[1;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m                     \u001b[1;34mf\"Expected: {expected_classes}, got {classes}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137], got ['(vertigo) Paroymsal  Positional Vertigo' 'AIDS'\n 'Accidentcerebrovascular' 'Acne' 'Adenocarcinoma' 'Affect Labile'\n 'Alcoholic hepatitis' 'Allergy' \"Alzheimer'S Disease\" 'Anxiety State'\n 'Aphasia' 'Arthritis' 'Asthma' 'Bacteremia'\n 'Benign Prostatic Hypertrophy' 'Bipolar Disorder' 'Bronchial Asthma'\n 'Bronchitis' 'Carcinoma Breast' 'Carcinoma Colon' 'Carcinoma Of Lung'\n 'Cardiomyopathy' 'Cervical spondylosis' 'Chicken pox' 'Cholecystitis'\n 'Chronic Alcoholic Intoxication' 'Chronic Kidney Failure'\n 'Chronic cholestasis' 'Cirrhosis' 'Colitis' 'Common Cold' 'Confusion'\n 'Coronary Heart Disease' 'Decubitus Ulcer' 'Deep Vein Thrombosis'\n 'Degenerativepolyarthritis' 'Delusion' 'Dementia' 'Dengue' 'Dependence'\n 'Depressive Disorder' 'Diabetes ' 'Dimorphic hemmorhoids(piles)'\n 'Diverticulitis' 'Diverticulosis' 'Drug Reaction' 'Edema Pulmonary'\n 'Emphysema Pulmonary' 'Encephalopathy' 'Endocarditis' 'Exanthema'\n 'Failure Heart' 'Failure Heart Congestive' 'Failure Kidney'\n 'Fibroid Tumor' 'Fungal infection' 'GERD' 'Gastroenteritis'\n 'Gastroesophageal Reflux Disease' 'Glaucoma' 'Gout' 'Heart attack'\n 'Hemiparesis' 'Hemorrhoids' 'Hepatitis' 'Hepatitis B' 'Hepatitis C'\n 'Hepatitis D' 'Hepatitis E' 'Hernia' 'Hyperbilirubinemia'\n 'Hypercholesterolemia' 'Hyperglycemia' 'Hyperlipidemia' 'Hypertension '\n 'Hypertension Pulmonary' 'Hypertensive Disease' 'Hyperthyroidism'\n 'Hypoglycemia' 'Hypothyroidism' 'Ileus' 'Impetigo' 'Incontinence'\n 'Infection' 'Influenza' 'Insufficiency Renal' 'Ischemia' 'Jaundice'\n 'Ketoacidosis Diabetic' 'Kidney Failure Acute' 'Lymphatic Diseases'\n 'Lymphoma' 'Malaria' 'Malignantneoplasms' 'Manic Disorder' 'Melanoma'\n 'Migraine' 'Migraine Disorders' 'Myocardial Infarction' 'Neoplasm'\n 'Neuropathy' 'Obesity' 'Oralcandidiasis' 'Osteoarthristis'\n 'Osteomyelitis' 'Overload Fluid' 'Pancreatitis' 'Pancytopenia'\n 'Paralysis (brain hemorrhage)' 'Paranoia' 'Parkinson Disease'\n 'Peptic ulcer diseae' 'Pericardial Effusion Body Substance'\n 'Peripheral Vascular Disease' 'Personality Disorder'\n 'Pneumocystiscariniipneumonia' 'Pneumonia' 'Pneumonia Aspiration'\n 'Pneumothorax' 'Primary Carcinoma Of The Liver Cells'\n 'Primary Malignant Neoplasm' 'Psoriasis' 'Psychotic Disorder'\n 'Pyelonephritis' 'Respiratory Failure' 'Schizophrenia'\n 'Sepsis (Invertebrate)' 'Suicide Attempt' 'Tachycardia Sinus' 'Thrombus'\n 'Tonic-Clonic Seizures' 'Transient Ischemic Attack' 'Tuberculosis'\n 'Typhoid' 'Upper Respiratory Infection' 'Urinary tract infection'\n 'Varicose veins' 'hepatitis A']"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b50c6b",
<<<<<<< HEAD

=======
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 7a8519d2f3dd6bb0cb396a7661bcbdafd4fea19f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 96.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create an SVM classifier\n",
    "model = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"SVM Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 6,
   "id": "85c21edd",

=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "execution_count": 15,
   "id": "03de958a",
<<<<<<< HEAD

=======
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 7a8519d2f3dd6bb0cb396a7661bcbdafd4fea19f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 96.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a KNN classifier\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"KNN Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 7,
   "id": "ea1d8b6f",

=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "execution_count": 23,
   "id": "9b9a26e3",
<<<<<<< HEAD

=======
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 7a8519d2f3dd6bb0cb396a7661bcbdafd4fea19f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 96.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Naive Bayes Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 8,
   "id": "1b375589",

=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "execution_count": 26,
   "id": "00e12c2f",
<<<<<<< HEAD

=======
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 7a8519d2f3dd6bb0cb396a7661bcbdafd4fea19f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.1671612265084075\n",
      "SVM Accuracy: 0.9683481701285855\n",
      "KNN Accuracy: 0.9683481701285855\n",
      "Voting Classifier Accuracy: 0.9683481701285855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# AdaBoost Classifier\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)  # You can use any classifier as the base learner\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "\n",
    "# Support Vector Machine (SVM) Classifier\n",
    "svm_classifier = SVC(probability=True, kernel='linear', C=1.0)\n",
    "\n",
    "# K-Nearest Neighbors (KNN) Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Voting Classifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('adaboost', adaboost_classifier),\n",
    "        ('svm', svm_classifier),\n",
    "        ('knn', knn_classifier)\n",
    "    ],\n",
    "    voting='soft'  # 'hard' for majority voting, 'soft' for weighted voting based on probabilities\n",
    ")\n",
    "\n",
    "# Train the classifiers\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "adaboost_pred = adaboost_classifier.predict(X_test)\n",
    "svm_pred = svm_classifier.predict(X_test)\n",
    "knn_pred = knn_classifier.predict(X_test)\n",
    "voting_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "print(f\"AdaBoost Accuracy: {accuracy_score(y_test, adaboost_pred)}\")\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, svm_pred)}\")\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, knn_pred)}\")\n",
    "print(f\"Voting Classifier Accuracy: {accuracy_score(y_test, voting_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 9,
   "id": "fe716730",

=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "execution_count": 28,
   "id": "f25c8914",
<<<<<<< HEAD

=======
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 7a8519d2f3dd6bb0cb396a7661bcbdafd4fea19f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.09792284866468842\n",
      "SVM Accuracy: 0.9683481701285855\n",
      "KNN Accuracy: 0.9683481701285855\n",
      "Random Forest Accuracy: 0.9683481701285855\n",
      "Voting Classifier Accuracy: 0.9683481701285855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree Classifier\n",
    "base_classifier_dt = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Support Vector Machine (SVM) Classifier\n",
    "base_classifier_svm = SVC(probability=True, kernel='linear', C=1.0)\n",
    "\n",
    "# K-Nearest Neighbors (KNN) Classifier\n",
    "base_classifier_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Random Forest Classifier\n",
    "base_classifier_rf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "\n",
    "# Voting Classifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('decision_tree', base_classifier_dt),\n",
    "        ('svm', base_classifier_svm),\n",
    "        ('knn', base_classifier_knn),\n",
    "        ('random_forest', base_classifier_rf)\n",
    "    ],\n",
    "    voting='soft'  # 'hard' for majority voting, 'soft' for weighted voting based on probabilities\n",
    ")\n",
    "\n",
    "# Train the classifiers\n",
    "base_classifier_dt.fit(X_train, y_train)\n",
    "base_classifier_svm.fit(X_train, y_train)\n",
    "base_classifier_knn.fit(X_train, y_train)\n",
    "base_classifier_rf.fit(X_train, y_train)\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dt_pred = base_classifier_dt.predict(X_test)\n",
    "svm_pred = base_classifier_svm.predict(X_test)\n",
    "knn_pred = base_classifier_knn.predict(X_test)\n",
    "rf_pred = base_classifier_rf.predict(X_test)\n",
    "voting_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test, dt_pred)}\")\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, svm_pred)}\")\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, knn_pred)}\")\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_pred)}\")\n",
    "print(f\"Voting Classifier Accuracy: {accuracy_score(y_test, voting_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 10,
   "id": "e99d99ab",

=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "execution_count": 32,
   "id": "8b8a5498",
<<<<<<< HEAD

=======
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 7a8519d2f3dd6bb0cb396a7661bcbdafd4fea19f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9683481701285855\n",
      "Gradient Boosting Accuracy: 0.1493570722057369\n",
      "SVM Accuracy: 0.9683481701285855\n",
      "KNN Accuracy: 0.9683481701285855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Decision Tree Accuracy: 0.09792284866468842\n",
      "SVM Accuracy: 0.9683481701285855\n",
      "KNN Accuracy: 0.9683481701285855\n",
      "Random Forest Accuracy: 0.9683481701285855\n",
=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
      "AdaBoost Accuracy: 0.1671612265084075\n",
      "Voting Classifier Accuracy: 0.9683481701285855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree Classifier\n",
    "base_classifier_dt = DecisionTreeClassifier(max_depth=5)\n",
    "base_classifier_dt.fit(X_train, y_train)\n",
    "dt_pred = base_classifier_dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
<<<<<<< HEAD
    "# Support Vector Machine (SVM) Classifier\n",
    "base_classifier_svm = SVC(probability=True, kernel='linear', C=1.0)\n",
    "base_classifier_svm.fit(X_train, y_train)\n",
    "svm_pred = base_classifier_svm.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
=======
    "# RandomForest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_pred = rf_classifier.predict(X_test)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_pred)}\")\n",
    "\n",
    "# GradientBoosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=20, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "gb_pred = gb_classifier.predict(X_test)\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_score(y_test, gb_pred)}\")\n",
    "\n",
    "# SVM Classifier\n",
    "svm_classifier = SVC(probability=True, kernel='linear', C=1.0)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_pred = svm_classifier.predict(X_test)\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, svm_pred)}\")\n",
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
    "\n",
    "# K-Nearest Neighbors (KNN) Classifier\n",
    "base_classifier_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "base_classifier_knn.fit(X_train, y_train)\n",
    "knn_pred = base_classifier_knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "\n",
    "# Random Forest Classifier\n",
    "base_classifier_rf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "base_classifier_rf.fit(X_train, y_train)\n",
    "rf_pred = base_classifier_rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# AdaBoost Classifier\n",
    "base_classifier_ada = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "base_classifier_ada.fit(X_train, y_train)\n",
    "ada_pred = base_classifier_ada.predict(X_test)\n",
    "ada_accuracy = accuracy_score(y_test, ada_pred)\n",
    "\n",
    "# Voting Classifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('decision_tree', base_classifier_dt),\n",
    "        ('svm', base_classifier_svm),\n",
    "        ('knn', base_classifier_knn),\n",
    "        ('random_forest', base_classifier_rf),\n",
    "        ('ada_boost', base_classifier_ada)\n",
    "    ],\n",
    "    voting='soft'  # 'hard' for majority voting, 'soft' for weighted voting based on probabilities\n",
    ")\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "voting_pred = voting_classifier.predict(X_test)\n",
    "voting_accuracy = accuracy_score(y_test, voting_pred)\n",
    "\n",
    "# Print accuracies together\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
    "print(f\"KNN Accuracy: {knn_accuracy}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(f\"AdaBoost Accuracy: {ada_accuracy}\")\n",
    "print(f\"Voting Classifier Accuracy: {voting_accuracy}\")\n"
   ]
<<<<<<< HEAD
=======
<<<<<<< HEAD
=======
<<<<<<< HEAD
=======
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49ee86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d08a94",
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
=======
>>>>>>> 59603c20d75bea00ec02a6ca748d0c40637d762f
>>>>>>> 4c49a45e1b1e9f587590268b4332382b5fda4fd7
>>>>>>> c3fc892b5456dc3ea6dd57db2b5946d81bb6c7c3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
